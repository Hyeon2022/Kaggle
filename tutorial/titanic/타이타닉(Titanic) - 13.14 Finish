타이타닉 튜토리얼에 대한 마무리를 해보겠습니다.

정확도를 높이기 위해서는 여러 기법을 사용해야하는데 

여러 기법은 이후에 다시 설명 드리겠습니다. 

우선 sklearn을 이용하여 모델을 구축하겠습니다.

 

 

from sklearn.ensemble import RandomForestClassifier #결정트리를 랜덤하게 만드는 것
from sklearn import metrics
from sklearn.model_selection import train_test_split #sklearn에는 머신러닝 모델을 위한 모듈이 다 들어가 있음.
sklearn에는 머신러닝을 위한 모델이 모두 들어가 있습니다. 따라서 sklearn을 이용한 모델 구축방법은 계속 해서 익히면 됩니다.

X_train = df_train.drop('Survived', axis = 1).values #세로 축으로 떼어내는 것
target_label = df_train['Survived'].values
X_test = df_test.values
아래와 같이 Survived를 데이터에서 세로축으로 떼어내고 train set과 test set을 만들어 냅니다.

 

X_tr, X_vid, y_tr, y_vid = train_test_split(X_train, target_label, test_size = 0.3, random_state = 2022)
다음과 같은 코드를 통해 train, test, validation으로 나누는 작업을 진행합니다. 이때 test_size가 0.3은 30%로 할당한다는 뜻이고

random_state = 2022라는 뜻은 랜덤으로 2022번 무작위로 섞는 것을 의미합니다.

 

이제 모델을 구축해보겠습니다.

model = RandomForestClassifier()
model.fit(X_tr, y_tr)
prediction = model.predict(X_vid)
이와 같은 코드를 통해 모델을 구축할 수 있습니다.

이를 통해 다음과 같은 결과값을 알 수 있습니다.

print('총 {}명 중 {: .2f}% 정확도로 생존 맞춤'.format(y_vid.shape[0], 100 * metrics.accuracy_score(prediction, y_vid)))
총 268명 중  83.96% 정확도로 생존 맞춤
(prediction == y_vid).sum()/ prediction.shape[0]
0.8395522388059702
 

 

 

 

이제 정확도를 나타낼 때 어떤 Feature가 더 정확한지 알아내는 작업을 해보겠습니다.

model.feature_importances_
from pandas import Series
feature_importance = model.feature_importances_
Series_feat_imp = Series(feature_importance, index = df_test.columns)
plt.figure(figsize = (8,8))
Series_feat_imp. sort_values(ascending = True).plot.barh()
plt.xlabel('Feature importance')
plt.ylabel('Feature')
plt.show()


#위의 결과를 통해 가설을 만들 수 있다. Fare, Age, Sex, Pclasse등이 중요하다.

 

다음과 같이 중요한 Featurerk Fare, Age, Pclass 순서임을 알 수 있습니다. 따라서 정확도를 올리기 위해서는 feature를 처리하는 방법을 공부해야 합니다.

 

이제 끝으로 제출하는 방법을 설명 드리겠습니다.

 

 

#파일 제출하기

submission = pd.read_csv('../input/titanic/gender_submission.csv')
submission.head()
prediction = model.predict(X_test)
submission['Survived'] = prediction
 
submission.to_csv('./my_first_submission.csv', index = False)
